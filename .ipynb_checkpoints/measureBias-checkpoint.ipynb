{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/nirbhey/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import StanfordTagger\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import os\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# politicalentities = open(os.getcwd()+\"/src/politicalentities.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importModel(publication):\n",
    "    \n",
    "    directory = 'models/publicationsCbow/'+publication\n",
    "#     directory = 'models/'+publication\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".model\"):\n",
    "            \n",
    "            splittedFileName = (filename.split('.')[0]).split('-')\n",
    "            exec(publication.replace(\" \", \"\") + \"Model = Word2Vec.load(\\\"/Users/nirbhey/Desktop/temp/\" + directory + \"/\" + filename + \"\\\")\", globals())\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f\n",
    "\n",
    "# positive sentiment : (compound score >= 0.05)\n",
    "# neutral sentiment : (compound score > -0.05) and (compound score < 0.05)\n",
    "# negative sentiment : (compound score <= -0.05)\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentimentAnalyserScores(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "#     print(type(score))\n",
    "#     print(\"{:-<40} {}\".format(sentence, str(score)))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relatedSentiment(model.most_similar(positive=['obama'], topn = 300))\n",
    "def relatedSentiment(mostSimilar):\n",
    "    similarityAndSentiment = {}\n",
    "    sentiments=[]\n",
    "    posTotal=0\n",
    "    negTotal=0\n",
    "    neuTotal=0\n",
    "    i = 0\n",
    "    standardiser = 1\n",
    "    \n",
    "    for tuple in mostSimilar:\n",
    "        \n",
    "        if i >= 100:\n",
    "            break\n",
    "            \n",
    "        word = nltk.word_tokenize(tuple[0])\n",
    "        \n",
    "        if 'JJ' not in nltk.pos_tag(word)[0][1] and 'RB' not in nltk.pos_tag(word)[0][1]:\n",
    "            continue\n",
    "        else:\n",
    "            similarityAndSentiment[tuple[1]] = sentimentAnalyserScores(tuple[0])\n",
    "            i += 1\n",
    "    \n",
    "    if i<100:\n",
    "        if i != 0:\n",
    "            standardiser = 100/i\n",
    "        else:\n",
    "            standardiser = 1\n",
    "\n",
    "    for similarity in similarityAndSentiment:\n",
    "        \n",
    "        posTotal += similarityAndSentiment[similarity][\"pos\"] * similarity * standardiser\n",
    "        negTotal += similarityAndSentiment[similarity][\"neg\"] * similarity * standardiser\n",
    "        neuTotal += similarityAndSentiment[similarity][\"neu\"] * similarity * standardiser\n",
    "        \n",
    "    return {'pos':posTotal,'neu':neuTotal,'neg':negTotal}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateBias(model,publication,file):\n",
    "#     file = open(\"models/\"+publication+\"/biasresults.txt\", \"w\")\n",
    "    file.write(\"Publication:\\n\")\n",
    "    file.write(\"\\tPolitical Entity    :\\tposTotal:neuTotal:negTotal\\n\")\n",
    "    file.write(publication+\":\\n\")\n",
    "    \n",
    "    for line in politicalentities:\n",
    "        \n",
    "        if line.strip() == '-':\n",
    "            file.write(\"\\t-----------------------------------------------------------------------------------------\\n\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            \n",
    "            file.write(\"\\t{0:20}:\\t{1:20}  :{2:20} :{3:20}\\n\".format(line.strip(),relatedSentiment(model.most_similar(positive=[line.strip()], topn=300))[\"pos\"],relatedSentiment(model.most_similar(positive=[line.strip()], topn=300))[\"neu\"],relatedSentiment(model.most_similar(positive=[line.strip()], topn=300))[\"neg\"]))     \n",
    "        \n",
    "        except KeyError:\n",
    "            \n",
    "            file.write(\"\\t{0:20}:\\t{1}\\n\".format(line.strip(),\"Word not in vocabulary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "america\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPos:0.0\n",
      "american\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "border\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "boris\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "bush\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "caucasian\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "christian\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "christianity\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "cia\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "conservative\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "constitution\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "discrimination\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "evangelic\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "evangelical\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "fbi\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "fox\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "gop\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "gun\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "guns\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "ice\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "israel\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "jerusalem\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "johnson\n",
      "\n",
      "\n",
      "\tPos:1.0\n",
      "libertarian\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "libertarianism\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "man\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "marine\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "marriage\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "men\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "military\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "nixon\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "nra\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "officer\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "pence\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "police\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "reagan\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "religion\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "religious\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "republican\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "shooting\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "soldier\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "states\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "texas\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "tradition\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "trump\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "veteran\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "wall\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "white\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "activism\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "activist\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "african\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "biden\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "black\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "california\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "californian\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "canada\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "cannabis\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "clinton\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "cnn\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "communism\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "communist\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "corbyn\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "democrat\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "democratic\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "equality\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "eu\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "foreign\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "foreigners\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "gay\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "germany\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "healthcare\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "immigrant\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "immigrants\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "islam\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "islamic\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "islamist\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "lgbt\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "lgbtq\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "lgbtqiap\n",
      "\n",
      "\n",
      "liberal\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "medicare\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "mexicans\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "mexico\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "muslim\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "palestine\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "refugee\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "refugees\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "russia\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "sjw\n",
      "\n",
      "\n",
      "socialism\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "socialist\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "sweden\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "tax\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "trans\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "transgender\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "uk\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "woman\n",
      "\n",
      "\n",
      "\tPos:0.0\n",
      "women\n",
      "\n",
      "\n",
      "\tPos:0.0\n"
     ]
    }
   ],
   "source": [
    "publications = ['New York Times','CNN', 'Breitbart', 'New York Post', 'Guardian', 'NPR', 'Reuters', 'Vox', 'Washington Post', 'Atlantic', 'Fox News', 'Buzzfeed News', 'National Review']\n",
    "# politicalentities = open(os.getcwd()+\"/src/politicalentities.txt\", \"r\")\n",
    "for publicationName in publications:\n",
    "    politicalentities = open(os.getcwd()+\"/src/politicalentities.txt\", \"r\")\n",
    "    importModel(publicationName)\n",
    "    exec(publicationName.replace(\" \", \"\")+\"BiasFile = open(\\\"\"+os.getcwd()+\"/models/publicationsCbow/\"+publicationName+\"/biasresults.txt\\\", \\\"w\\\")\",globals())\n",
    "    exec(\"evaluateBias(\"+publicationName.replace(\" \", \"\")+\"Model,\\\"\"+publicationName+\"\\\",\"+publicationName.replace(\" \", \"\")+\"BiasFile)\")\n",
    "    exec(publicationName.replace(\" \", \"\")+\"BiasFile.close()\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
